# -*- coding: utf-8 -*-
"""(AppleProducts)DataCrawling.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LBK7jZgNHvRUtsytKgwqsfpktAlAFrhY
"""

#@title Twitter Auth Token
#Siswa

twitter_auth_token = 'c4b1574e197b99fdb285d8a4034c501d423b669b'

"""# Installing Libraries"""

# Import required Python package
!pip install pandas

# Install Node.js (because tweet-harvest built using Node.js)
!sudo apt-get update
!sudo apt-get install -y ca-certificates curl gnupg
!sudo mkdir -p /etc/apt/keyrings
!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg

!NODE_MAJOR=20 && echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | sudo tee /etc/apt/sources.list.d/nodesource.list

!sudo apt-get update
!sudo apt-get install nodejs -y

!node -v

"""## List of Positive, Negative & Characteristics Keywords

---


"""

# Crawl Data

filename = 'iphone16.csv'

# Define positive and negative keywords for iPhone and Samsung along with product characteristics
positive_keywords = (
    "love OR loved OR amazing OR amazed OR best OR excellent OR fantastic OR great OR affordable OR user-friendly OR "
    "impressive OR worth OR incredible OR fast OR smooth OR reliable OR advanced OR awesome OR innovative OR "
    "powerful OR exceptional OR premium OR elegant OR stylish OR efficient OR beautiful OR unique OR "
    "top-notch OR next-level OR iconic OR ontop OR perfect OR revolutionary OR flawless OR outstanding OR superior OR "
    "amazingexperience OR favorite OR LOVE OR AMAZING OR BEST OR EXCELLENT OR FANTASTIC OR GREAT OR AFFORDABLE OR "
    "USER-FRIENDLY OR IMPRESSIVE OR WORTH OR INCREDIBLE OR FAST OR SMOOTH OR RELIABLE OR ADVANCED OR AWESOME OR "
    "INNOVATIVE OR POWERFUL OR EXCEPTIONAL OR PREMIUM OR ELEGANT OR STYLISH OR EFFICIENT OR BEAUTIFUL OR UNIQUE OR "
    "TOP-NOTCH OR NEXT-LEVEL OR ICONIC OR PERFECT OR REVOLUTIONARY OR FLAWLESS OR OUTSTANDING OR SUPERIOR OR "
    "AMAZINGEXPERIENCE OR FAVORITE OR Love OR Amazing OR Best OR Excellent OR Fantastic OR Great OR Affordable OR "
    "User-Friendly OR Impressive OR Worth OR Incredible OR Fast OR Smooth OR Reliable OR Advanced OR Awesome OR "
    "Innovative OR Powerful OR Exceptional OR Premium OR Elegant OR Stylish OR Efficient OR Beautiful OR Unique OR "
    "Top-Notch OR Next-Level OR Iconic OR Perfect OR Revolutionary OR Flawless OR Outstanding OR Superior OR "
    "AmazingExperience OR Favorite"
)
negative_keywords = (
    "disappointing OR dissapointed OR not worst OR terrible OR frustrating OR buggy OR overpriced OR unresponsive OR overheating OR "
    "not worth OR unreliable OR slow OR laggy OR expensive OR overhyped OR annoying OR poor OR lacking OR broken OR "
    "unstable OR useless OR complicated OR glitchy OR underwhelming OR weak OR outdated OR frustrated OR unimpressed OR "
    "bad OR unsatisfied OR unacceptable OR irritating OR problematic OR disliked OR hated OR DISAPPOINTING OR WORST OR "
    "TERRIBLE OR FRUSTRATING OR BUGGY OR OVERPRICED OR UNRESPONSIVE OR OVERHEATING OR NOT WORTH OR UNRELIABLE OR SLOW OR "
    "LAGGY OR EXPENSIVE OR OVERHYPED OR ANNOYING OR POOR OR LACKING OR BROKEN OR UNSTABLE OR USELESS OR COMPLICATED OR "
    "GLITCHY OR UNDERWHELMING OR WEAK OR OUTDATED OR FRUSTRATED OR UNIMPRESSED OR BAD OR UNSATISFIED OR UNACCEPTABLE OR "
    "IRRITATING OR PROBLEMATIC OR DISLIKED OR HATED OR Disappointing OR Worst OR Terrible OR Frustrating OR Buggy OR "
    "Overpriced OR Unresponsive OR Overheating OR Not Worth OR Unreliable OR Slow OR Laggy OR Expensive OR Overhyped OR "
    "Annoying OR Poor OR Lacking OR Broken OR Unstable OR Useless OR Complicated OR Glitchy OR Underwhelming OR Weak OR "
    "Outdated OR Frustrated OR Unimpressed OR Bad OR Unsatisfied OR Unacceptable OR Irritating OR Problematic OR Disliked OR Hated"
)

characteristics_keywords = (
    "camera OR photography OR photo OR night mode OR night photography OR zoom OR portrait mode OR video OR video quality OR cinematic mode OR stabilization OR cinematic OR panorama OR ultrawide OR HDR OR"
    "display OR DOLBY OR screen OR refresh rate OR OLED OR brightness OR resolution OR Dynamic Island OR bezel OR notch OR "
    "battery OR wireless OR battery life OR battery health OR endurance OR charging OR fast charging OR wireless charging OR "
    "performance OR storage OR RAM OR memory OR processor OR chipset OR A18 Bionic OR benchmark OR speed OR gaming OR multitasking OR "
    "design OR build quality OR material OR size OR weight OR colors OR MagSafe OR port OR "
    "operating system OR OR OS OR iOS OR updates OR bugs OR features OR software OR customization OR compatibility OR integration OR "
    "price OR affordability OR value OR "
    "connectivity OR Wi-Fi OR Bluetooth OR cellular OR Dual SIM OR eSIM OR 5G OR "
    "ecosystem OR OR magsafe OR integration OR comparison OR Vs Samsung OR Vs Android OR accessibility OR ease of use"
)
## for iPhone 15 (A16 Bionic)

# Define keywords for both iPhone 16
product_keywords = '(iPhone16 OR iPhone 16 OR iphone16 OR iphone 16 OR IPHONE16 OR IPHONE 16 OR Iphone16 OR Iphone 16)'

# Define keywords for both iPhone 15
#product_keywords = '(iPhone15 OR iPhone 15 OR iphone15 OR iphone 15 OR IPHONE15 OR IPHONE 15 OR Iphone15 OR Iphone 15)'

# Combine all the keywords (positive, negative, characteristics, and product names)
search_keyword = f"({product_keywords} AND ({positive_keywords} OR {negative_keywords} OR {characteristics_keywords})) since:2024-08-01 until:2024-12-31 lang:en"

limit = 10000

# Crawl data using tweet-harvest with the search query
!npx -y tweet-harvest@2.6.1 -o "{filename}" -s "{search_keyword}" --tab "LATEST" -l {limit} --token {twitter_auth_token}

import pandas as pd

# Specify the path to your CSV file
file_path = f"tweets-data/{filename}"

# Read the CSV file into a pandas DataFrame
df = pd.read_csv(file_path, delimiter=",")

# Display the DataFrame
display(df)

# Check the number of tweets

num_tweets = len(df)
print(f"Number of tweets in the dataframe: {num_tweets}.")

"""## Handling Spam Text & duplicate datas
---



"""

# List of spam-related keywords
spam_keywords = [
    'deals', 'coupon', 'discount', 'promo', 'offer',
    'link', 'http', 'https', 'shop', 'sale', 'Temu', 'read', "find"
]

# Filter function to remove spam-related tweets
def is_relevant_tweet(tweet):
    for keyword in spam_keywords:
        if keyword in tweet.lower():
            return False
    return True


# Apply filters
df['relevant'] = df['full_text'].apply(is_relevant_tweet)  # Assuming 'content' is the tweet text column
df_relevant = df[df['relevant']].drop(columns=['relevant'])

# Drop duplicate tweets
df_relevant = df_relevant.drop_duplicates(subset=['full_text'])

# Display filtered dataset
print(f"Number of filtered tweets: {len(df_relevant)}.")
display(df_relevant.head())

"""## Save the data in CSV file"""

# Save the filtered dataset
cleaned_filename = "iphone16_cleaned.csv"
df_relevant.to_csv(cleaned_filename, index=False)
print(f"Filtered tweets saved to {cleaned_filename}.")

# Count the number of rows (which represents the number of tweets) in the cleaned DataFrame
num_cleaned_tweets = len(df_relevant)

print(f"Number of tweets in the cleaned file: {num_cleaned_tweets}")